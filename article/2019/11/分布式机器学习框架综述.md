*作者：[Quan Chen](https://github.com/chenquan)*

# 分布式机器学习框架综述

最近公司业务中有做分布式机器学习的需求，相比单机的算法训练和算法调优来说分布式的方式将极大的提供我们的生产效率，加快模型的探索过程。

## 一. 深度学习

深度学习的分布式训练可以通过两种方式实现：数据并行化和模型并行化。

### 1. 数据并行化

数据并行化的目标是将数据集均等地分配到系统的各个节点（node），其中每个节点都有该神经网络的一个副本及其本地的权重。每个节点都会处理该数据集的一个不同子集并更新其本地权重集。这些本地权重会在整个集群中共享，从而通过一个累积算法计算出一个新的全局权重集。这些全局权重又会被分配至所有节点，然后节点会在此基础上处理下一批数据。

### 2. 模型并行化

模型并行化则是通过将该模型的架构切分到不同的节点上来实现训练的分布化。AlexNet 是使用模型并行化的最早期模型之一，其方法是将网络分摊到 2 个 GPU 上以便模型能放入内存中。当模型架构过大以至于无法放入单台机器且该模型的某些部件可以并行化时，才能应用模型并行化。




### 3. 深度学习分布式框架介绍
#### 3.1 TensorFlowOnSpark框架

>  *TensorFlowOnSpark为Apache Hadoop和Apache Spark集群带来了可扩展的深度学习。* 

*TensorFlowOnSpark* 是雅虎(Yahoo)开源的基于TensorFlow和Spark集群的分布式深度学习框架

通过将[TensorFlow](https://www.tensorflow.org/)深度学习框架中的突出功能与[Apache Spark](http://spark.apache.org/)和[Apache Hadoop相结合](http://hadoop.apache.org/)，TensorFlowOnSpark可以在GPU和CPU服务器集群上实现分布式深度学习。

它可以在Spark集群上同时进行分布式TensorFlow训练和推理，其目标是最大程度地减少在共享网格上运行现有TensorFlow程序所需的代码更改量。其Spark兼容API通过以下步骤帮助管理TensorFlow集群：

1. **启动** -在执行程序上启动Tensorflow主要功能，以及数据/控制消息的侦听器。
2. **数据获取**
   - **InputMode.TENSORFLOW-**利用TensorFlow的内置API直接从HDFS读取数据文件。
   - **InputMode.SPARK-**通过`TFNode.DataFeed`类将Spark RDD数据发送到TensorFlow节点。请注意，我们利用[Hadoop输入/输出格式](https://github.com/tensorflow/ecosystem/tree/master/hadoop)来访问HDFS上的TFRecords。
3. **关闭** -关闭执行程序上的Tensorflow工作程序和PS节点。

##### 优势

 与替代的深度学习解决方案相比，TensorFlowOnSpark具有一些重要的优势 :

- 只需不到10行代码更改即可轻松迁移现有TensorFlow程序。
- 支持所有TensorFlow功能：同步/异步训练，模型/数据并行性，推理和TensorBoard。
- 服务器到服务器直接通信在可用时可以更快地学习。
- 允许HDFS上的数据集以及由Spark推送或由TensorFlow推送的其他来源。
- 轻松与您现有的Spark数据处理管道集成。
- 轻松部署在云或本地以及CPU或GPU上。

> 目前TensorFlowOnSpark已经支持最新版本的TensorFlow,即TensorFlow 2.0. 

## 二. (传统)机器学习

刚刚说了深度学习的分布式算法,现在来谈谈传统机器学习的分布式框架.

### 1. spark-sklearn

Scikit-learn是传统机器学习算法中常用的框架,但是,Scikit-learn的优势通常在于单个节点上的计算领域。对于某些常见方案，例如参数调整，可以并行运行大量小任务。这些场景对应Spark简直完美,因此将Spark和Scikit-learn结合,使用Spark集群对训练任务进行分工和调度将会加快训练过程.
由[Databricks](https://databricks.com/)开源的spark-sklearn框架,它结合了Spark和scikit-learn的优势,无需更改用户代码就可实现分布式训练。它重新实现了scikit-learn的某些组件,用户将看到与scikit-learn的交叉验证工具完全兼容的基于Spark的交叉验证器类。通过交换单个类导入，用户可以为他们现有的scikit-learn工作流分配交叉验证。

### 2. XGBoost

XGBoost是由陈天奇大佬开发并开源的分布式梯度提升库, 旨在**高效**，**灵活**且**可移植**。它在[Gradient Boosting](https://en.wikipedia.org/wiki/Gradient_boosting)框架下实现了机器学习算法。XGBoost提供了并行树增强（也称为GBDT，GBM），可快速准确地解决许多数据科学问题。相同的代码在主要的分布式环境（Hadoop，SGE，MPI）上运行，并且可以解决数十亿个示例之外的问题。 

XGBoost目前可以说是各大数据科学竞赛的夺冠神器,许多冠军团队都有使用到它,并且在工业领域运用也是非常广.

### 3. LightGBM

LightGBM基于决策树算法的快速，分布式，高性能梯度提升（GBT，GBDT，GBRT，GBM或MART）框架，用于排名，分类和许多其他机器学习任务。 

LightGBM是微软开源的基于树的学习算法的梯度提升框架,作为数据科学竞赛和工业领域落地实现的后起之秀,凭借着其训练速度更快，效率更高,降低内存使用率等特性在XGBoost独霸天下的情况下也分得了一杯羹.除此之外,LightGBM同样是一个支持并行和GPU学习,能够处理大规模数据的分布式框架

